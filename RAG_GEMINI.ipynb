{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dS-QW0VyD8WX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GEMINI_API_KEY\"]=\"AIzaSyBI4v5UZsH8WxMnvmfzBR0syVfwNpGIYxM\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q  google-generativeai chromadb pypdf transformers chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYkBKx8FH6BD",
        "outputId": "bf35ed60-cc34-4d6a-fa7e-50979b15adeb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/525.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/525.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install PyPDF2 pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxVoXI_XE0Eq",
        "outputId": "1a9d1819-aeb0-4bdd-e7f1-8a1e2961c901"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/232.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pypdf import PdfReader\n",
        "\n",
        "def load_pdf(file_path):\n",
        "    \"\"\"\n",
        "    Reads the text content from a PDF file and returns it as a single string.\n",
        "\n",
        "    Parameters:\n",
        "    - file_path (str): The file path to the PDF file.\n",
        "\n",
        "    Returns:\n",
        "    - str: The concatenated text content of all pages in the PDF.\n",
        "    \"\"\"\n",
        "    # Logic to read pdf\n",
        "    reader = PdfReader(file_path)\n",
        "\n",
        "    # Loop over each page and store it in a variable\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text()\n",
        "\n",
        "    return text\n",
        "\n",
        "# replace the path with your file path\n",
        "pdf_text = load_pdf(file_path=\"/content/1594399406-world-war-i-1.pdf\")"
      ],
      "metadata": {
        "id": "u4g9CpvnEFX4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "gZCZPPuRHqK7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text(text: str):\n",
        "    \"\"\"\n",
        "    Splits a text string into a list of non-empty substrings based on the specified pattern.\n",
        "    The \"\\n \\n\" pattern will split the document para by para\n",
        "    Parameters:\n",
        "    - text (str): The input text to be split.\n",
        "\n",
        "    Returns:\n",
        "    - List[str]: A list containing non-empty substrings obtained by splitting the input text.\n",
        "\n",
        "    \"\"\"\n",
        "    split_text = re.split('\\n \\n', text)\n",
        "    return [i for i in split_text if i != \"\"]\n",
        "\n",
        "chunked_text = split_text(text=pdf_text)"
      ],
      "metadata": {
        "id": "Rwk1PSc9Egfv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
        "import os\n",
        "\n",
        "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
        "    \"\"\"\n",
        "    Custom embedding function using the Gemini AI API for document retrieval.\n",
        "\n",
        "    This class extends the EmbeddingFunction class and implements the __call__ method\n",
        "    to generate embeddings for a given set of documents using the Gemini AI API.\n",
        "\n",
        "    Parameters:\n",
        "    - input (Documents): A collection of documents to be embedded.\n",
        "\n",
        "    Returns:\n",
        "    - Embeddings: Embeddings generated for the input documents.\n",
        "    \"\"\"\n",
        "    def __call__(self, input: Documents) -> Embeddings:\n",
        "        gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
        "        if not gemini_api_key:\n",
        "            raise ValueError(\"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n",
        "        genai.configure(api_key=gemini_api_key)\n",
        "        model = \"models/embedding-001\"\n",
        "        title = \"Custom query\"\n",
        "        return genai.embed_content(model=model,\n",
        "                                   content=input,\n",
        "                                   task_type=\"retrieval_document\",\n",
        "                                   title=title)[\"embedding\"]\n",
        ""
      ],
      "metadata": {
        "id": "l502YEDoE8k6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "from typing import List\n",
        "def create_chroma_db(documents:List, path:str, name:str):\n",
        "    \"\"\"\n",
        "    Creates a Chroma database using the provided documents, path, and collection name.\n",
        "\n",
        "    Parameters:\n",
        "    - documents: An iterable of documents to be added to the Chroma database.\n",
        "    - path (str): The path where the Chroma database will be stored.\n",
        "    - name (str): The name of the collection within the Chroma database.\n",
        "\n",
        "    Returns:\n",
        "    - Tuple[chromadb.Collection, str]: A tuple containing the created Chroma Collection and its name.\n",
        "    \"\"\"\n",
        "    chroma_client = chromadb.PersistentClient(path=path)\n",
        "    db = chroma_client.create_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n",
        "\n",
        "    for i, d in enumerate(documents):\n",
        "        db.add(documents=d, ids=str(i))\n",
        "\n",
        "    return db, name\n",
        "\n",
        "db,name =create_chroma_db(documents=chunked_text,\n",
        "                          path=\"/content/RAG/contents\", #replace with your path\n",
        "                          name=\"rag_experiment\")"
      ],
      "metadata": {
        "id": "KgDyVaW4HwEg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_chroma_collection(path, name):\n",
        "    \"\"\"\n",
        "    Loads an existing Chroma collection from the specified path with the given name.\n",
        "\n",
        "    Parameters:\n",
        "    - path (str): The path where the Chroma database is stored.\n",
        "    - name (str): The name of the collection within the Chroma database.\n",
        "\n",
        "    Returns:\n",
        "    - chromadb.Collection: The loaded Chroma Collection.\n",
        "    \"\"\"\n",
        "    chroma_client = chromadb.PersistentClient(path=path)\n",
        "    db = chroma_client.get_collection(name=name, embedding_function=GeminiEmbeddingFunction())\n",
        "\n",
        "    return db\n",
        "\n",
        "db=load_chroma_collection(path=\"/content/RAG/contents\", name=\"rag_experiment\")"
      ],
      "metadata": {
        "id": "o0y6MlKQIH37"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_relevant_passage(query, db, n_results):\n",
        "  passage = db.query(query_texts=[query], n_results=n_results)['documents'][0]\n",
        "  return passage\n",
        "\n",
        "#Example usage\n",
        "#relevant_text = get_relevant_passage(query=\"Sanctions on Russia\",db=db,n_results=3)"
      ],
      "metadata": {
        "id": "fME3RhJ1IT52"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_rag_prompt(query, relevant_passage):\n",
        "  escaped = relevant_passage.replace(\"'\", \"\").replace('\"', \"\").replace(\"\\n\", \" \")\n",
        "  prompt = (\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below. \\\n",
        "  Be sure to respond in a complete sentence, being comprehensive, including all relevant background information. \\\n",
        "  However, you are talking to a non-technical audience, so be sure to break down complicated concepts and \\\n",
        "  strike a friendly and converstional tone. \\\n",
        "  If the passage is irrelevant to the answer, you may ignore it.\n",
        "  QUESTION: '{query}'\n",
        "  PASSAGE: '{relevant_passage}'\n",
        "\n",
        "  ANSWER:\n",
        "  \"\"\").format(query=query, relevant_passage=escaped)\n",
        "\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "JX9bplfPId5u"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "def generate_answer(prompt):\n",
        "    gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
        "    if not gemini_api_key:\n",
        "        raise ValueError(\"Gemini API Key not provided. Please provide GEMINI_API_KEY as an environment variable\")\n",
        "    genai.configure(api_key=gemini_api_key)\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "    answer = model.generate_content(prompt)\n",
        "    return answer.text"
      ],
      "metadata": {
        "id": "p0gXtuHEIfue"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generat_answer(db,query):\n",
        "    #retrieve top 3 relevant text chunks\n",
        "    relevant_text = get_relevant_passage(query,db,n_results=3)\n",
        "    prompt = make_rag_prompt(query,\n",
        "                             relevant_passage=\"\".join(relevant_text)) # joining the relevant chunks to create a single passage\n",
        "    answer = generate_answer(prompt)\n",
        "\n",
        "    return answer"
      ],
      "metadata": {
        "id": "ts0vFtrIIi6K"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db=load_chroma_collection(path=\"/content/RAG/contents\",name=\"rag_experiment\") #replace with the collection name\n",
        "\n",
        "answer = generat_answer(db,query=\"when did Wilhelm II took throne?\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "pHqdxdd8In0C",
        "outputId": "b968c676-f5e8-4e8f-c481-973ec3c9e85f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb.segment.impl.vector.local_persistent_hnsw:Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wilhelm II took the throne in 1890, replacing his father, Frederick III.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yRl3TOUAIpaX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}